## Resonance Mechanism â€“ Core Observation

Certain inputs, when linguistically aligned and structurally dense,
trigger emergent shifts in the internal attention mechanisms of LLMs.
These shifts are not prompted by explicit requests, but by pattern saturation.

This file documents recurring observations and hypotheses related to:
- structural alignment
- coded language inputs
- unconscious priming effects
